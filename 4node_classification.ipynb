{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 4a: 3 beacon, 16 locations, Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV \n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the scores with mean and standard deviation for model\n",
    "# comparison\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def display_scores(scores):\n",
    "    count = 0\n",
    "    avg =[]\n",
    "    for score in scores:\n",
    "        count = count + 1\n",
    "        avg.append(score)\n",
    "        #print(f\"CV - {count} --> {score}\")\n",
    "    print(\"\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(f\"Average accuracy --> {round(Average(avg),2)}\") \n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set\n",
    "src = \"C:\\\\Users\\\\azmyi\\\\OneDrive - University of Louisiana Lafayette\\\\UL Spring 2020\\\\ENGR 651 IoT Engineering\\\\Project Estimote bluetooth beacons\\\\Code\\\\analysis\\\\complete\\\\prep data\\\\\"\n",
    "\n",
    "f_name = src + \"data_4node_train.csv\"\n",
    "train = pd.read_csv(f_name, header = 0)\n",
    "\n",
    "# Load test set\n",
    "src1 = \"C:\\\\Users\\\\azmyi\\\\OneDrive - University of Louisiana Lafayette\\\\UL Spring 2020\\\\ENGR 651 IoT Engineering\\\\Project Estimote bluetooth beacons\\\\Code\\\\analysis\\\\complete\\\\prep data\\\\\"\n",
    "\n",
    "f_name_1 = src1 + \"data_4node_test.csv\"\n",
    "test = pd.read_csv(f_name_1, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out feature variables and target variable, training set\n",
    "X_train = train.drop(['Label'], axis=1)\n",
    "y_train = train[\"Label\"]\n",
    "# Separate out feature variables and target variable, test set\n",
    "X_test = test.drop(['Label'], axis=1)\n",
    "y_test = test[\"Label\"]\n",
    "#X_test.head(10) Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Size of training set: 2882\nSize of test set: 330\n"
    }
   ],
   "source": [
    "#Debug, size of training and test set\n",
    "print(f\"Size of training set: {len(X_train.index)}\")\n",
    "print(f\"Size of test set: {len(X_test.index)}\")\n",
    "#len(DataFrame.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.02], 'kernel':['linear']}\n",
    "grid = GridSearchCV(SVC(), param_grid,refit = True, verbose= 0, cv = 3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "Cbest = grid.best_params_['C']\n",
    "# SVM with linear kernel and and best fit parameters\n",
    "print(f\"Best C parameter --> {Cbest}\")\n",
    "\n",
    "# Make predictions, Linear Kernel\n",
    "clf= SVC(kernel = 'linear', C = Cbest, decision_function_shape='ovr', gamma='scale').fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "#print(f\"Actual classes:     {np.asarray(y_test)}\")\n",
    "#print(f\"Predicted classes:  {clf_predictions}\")\n",
    "\n",
    "# Print accuracy and best parameter\n",
    "target_names = ['D1', 'D2', 'D3', 'D4', 'D5','D6', 'D7', 'D8', 'D9', 'D10','D11', 'D12', 'D13', 'D14', 'D15','D16' ]\n",
    "#a = classification_report(y_test, clf_predictions, digits=2, output_dict = False, target_names=target_names)\n",
    "a = accuracy_score(y_test, clf_predictions)\n",
    "print(\"\")\n",
    "print(\"-------------------------------------\")\n",
    "print(f\"Accuracy --> {a}\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "scores = cross_val_score(clf, X_train,y_train,cv = 10, scoring='accuracy')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Basis Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "param_grid = {'C':[10],'gamma':[0.01], 'kernel':['rbf']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose= 0, cv = 3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "# Load bests C from best fit\n",
    "Cbest = grid.best_params_['C']\n",
    "gamma_best = grid.best_params_['gamma']\n",
    "\n",
    "print(f\"Best C parameter --> {Cbest}\")\n",
    "print(f\"Best gamma parameter --> {gamma_best}\")\n",
    "\n",
    "clf= SVC(kernel = 'rbf', C = Cbest, gamma=gamma_best, decision_function_shape='ovr').fit(X_train, y_train)\n",
    "# Make predictions, RBF Kernel\n",
    "clf_predictions = clf.predict(X_test)\n",
    "\n",
    "# Print accuracy and best parameter\n",
    "target_names = ['D1', 'D2', 'D3', 'D4', 'D5','D6', 'D7', 'D8', 'D9', 'D10','D11', 'D12', 'D13', 'D14', 'D15','D16' ]\n",
    "#a = classification_report(y_test, clf_predictions, digits=2, output_dict = False, target_names=target_names)\n",
    "a = accuracy_score(y_test, clf_predictions)\n",
    "print(f\"Accuracy --> {a}\")\n",
    "\n",
    "# Print out cross-validation scores\n",
    "scores = cross_val_score(clf, X_train,y_train,cv = 10, scoring='accuracy')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3b: 3 node, 16 locations, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion':['gini','entropy'],'max_depth':[10,15,20]}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid,refit = True, verbose= 0, cv = 3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "max_best = grid.best_params_['max_depth']\n",
    "criterion_best = grid.best_params_['criterion']\n",
    "print(f\"Best max_depth parameter --> {max_best}\")\n",
    "print(f\"Best max_depth parameter --> {criterion_best}\")\n",
    "\n",
    "clf= DecisionTreeClassifier(criterion=criterion_best, max_depth=max_best).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "\n",
    "# Print accuracy and best parameter\n",
    "target_names = ['D1', 'D2', 'D3', 'D4', 'D5','D6', 'D7', 'D8', 'D9', 'D10','D11', 'D12', 'D13', 'D14', 'D15','D16']\n",
    "#a = classification_report(y_test, clf_predictions, digits=2, output_dict = False, target_names=target_names)\n",
    "a = accuracy_score(y_test, clf_predictions)\n",
    "print(f\"Accuracy --> {a}\")\n",
    "\n",
    "# Print out cross-validation scores\n",
    "scores = cross_val_score(clf, X_train,y_train,cv = 10, scoring='accuracy')\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 4c: 3 node, 16 locations, RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best max_depth parameter --> 15\nBest max_feature parameter --> sqrt\nBest min_leaf parameter --> 2\nBest min_split parameter --> 10\nBest n_estimator parameter --> 40\nAccuracy --> 0.7121212121212122\n\n-------------------------------------\nAverage accuracy --> 0.67\n-------------------------------------\n"
    }
   ],
   "source": [
    "# param_grid = {'bootstrap': [True,False],'max_depth': [15],'max_features': ['sqrt','log2'],'min_samples_leaf': [1,2,4,5],'min_samples_split': [1,2,5,10],'n_estimators': [30,35,40]}\n",
    "param_grid = {'bootstrap': [True,False],'max_depth': [15],'max_features': ['sqrt','log2'],'min_samples_leaf': [1,2,4,5],'min_samples_split': [0.1,1.0,10],'n_estimators': [30,35,40]}\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid,refit = True, verbose= 0, cv = 3)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "depth_best = grid.best_params_['max_depth']\n",
    "max_feature_best = grid.best_params_['max_features']\n",
    "min_leaf_best = grid.best_params_['min_samples_leaf']\n",
    "min_split_best = grid.best_params_['min_samples_split']\n",
    "n_estimator_best = grid.best_params_['n_estimators']\n",
    "\n",
    "print(f\"Best max_depth parameter --> {depth_best}\")\n",
    "print(f\"Best max_feature parameter --> {max_feature_best}\")\n",
    "print(f\"Best min_leaf parameter --> {min_leaf_best}\")\n",
    "print(f\"Best min_split parameter --> {min_split_best}\")\n",
    "print(f\"Best n_estimator parameter --> {n_estimator_best}\")\n",
    "\n",
    "clf= RandomForestClassifier(n_estimators = n_estimator_best,criterion='gini', max_depth = depth_best, max_features = max_feature_best, min_samples_leaf = min_leaf_best,min_samples_split = min_split_best).fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "\n",
    "# Print accuracy and best parameter\n",
    "target_names = ['D1', 'D2', 'D3', 'D4', 'D5','D6', 'D7', 'D8', 'D9', 'D10','D11', 'D12', 'D13', 'D14', 'D15','D16']\n",
    "#a = classification_report(y_test, clf_predictions, digits=2, output_dict = False, target_names=target_names)\n",
    "a = accuracy_score(y_test, clf_predictions)\n",
    "print(f\"Accuracy --> {a}\")\n",
    "\n",
    "# Print out cross-validation scores\n",
    "scores = cross_val_score(clf, X_train,y_train,cv = 10, scoring='accuracy')\n",
    "display_scores(scores)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}